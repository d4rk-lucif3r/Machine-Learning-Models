{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "Boltzmann Machine.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.4 64-bit"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "2951d919548ae18de2df5ded62b9a6d18db65d3b5a4ffaab87b83029c7c31e33"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Boltzmann Machine\r\n"
      ],
      "metadata": {
        "id": "K4f4JG1gdKqj",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading the dataset\r\n"
      ],
      "metadata": {
        "id": "1jbiqOK7dLGG",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML-100K\r\n"
      ],
      "metadata": {
        "id": "XL5MEkLcfRD2",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "source": [
        "# !wget \"http://files.grouplens.org/datasets/movielens/ml-100k.zip\"\r\n",
        "# !unzip ml-100k.zip\r\n",
        "# !ls"
      ],
      "outputs": [],
      "metadata": {
        "id": "rjOPzue7FCXJ",
        "colab_type": "code",
        "outputId": "44d3a628-f522-4d0d-efdf-009b7d3a28df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML-1M\r\n"
      ],
      "metadata": {
        "id": "9Xis6ldDfTs6",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "source": [
        "# !wget \"http://files.grouplens.org/datasets/movielens/ml-1m.zip\"\r\n",
        "# !unzip ml-1m.zip\r\n",
        "# !ls"
      ],
      "outputs": [],
      "metadata": {
        "id": "LOly1yfAfTjd",
        "colab_type": "code",
        "outputId": "22029b8c-79f2-46a2-a745-cdce83582b40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing the libraries\r\n"
      ],
      "metadata": {
        "id": "EOBJ8UCXdY0g",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.parallel\r\n",
        "import torch.optim as optim\r\n",
        "import torch.utils.data\r\n",
        "from torch.autograd import Variable"
      ],
      "outputs": [],
      "metadata": {
        "id": "_LvGeU1CeCtg",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing the dataset\r\n",
        "\r\n"
      ],
      "metadata": {
        "id": "pM04FyMudkoK",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "source": [
        "# We won't be using this dataset.\r\n",
        "movies = pd.read_csv('ml-1m/movies.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\r\n",
        "users = pd.read_csv('ml-1m/users.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\r\n",
        "ratings = pd.read_csv('ml-1m/ratings.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')"
      ],
      "outputs": [],
      "metadata": {
        "id": "UJw2p3-Cewo4",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing the training set and the test set\n"
      ],
      "metadata": {
        "id": "yTIbE2tkdkwP",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "source": [
        "training_set = pd.read_csv('ml-100k/u1.base', delimiter = '\\t')\r\n",
        "training_set = np.array(training_set, dtype = 'int')\r\n",
        "test_set = pd.read_csv('ml-100k/u1.test', delimiter = '\\t')\r\n",
        "test_set = np.array(test_set, dtype = 'int')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting the number of users and movies\n"
      ],
      "metadata": {
        "id": "zCf8HjSydk4s",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "source": [
        "nb_users = int(max(max(training_set[:,0]), max(test_set[:,0])))\r\n",
        "nb_movies = int(max(max(training_set[:,1]), max(test_set[:,1])))"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "source": [
        "print(nb_users,'|',nb_movies)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "943 | 1682\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting the data into an array with users in lines and movies in columns\n"
      ],
      "metadata": {
        "id": "J-w4-hVidlAm",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "source": [
        "def convert(data):\r\n",
        "    new_data = []\r\n",
        "    for id_users in range(1, nb_users + 1):\r\n",
        "        id_movies = data[:,1][data[:,0] == id_users]\r\n",
        "        id_ratings = data[:,2][data[:,0] == id_users]\r\n",
        "        ratings = np.zeros(nb_movies)\r\n",
        "        ratings[id_movies - 1] = id_ratings\r\n",
        "        new_data.append(list(ratings))\r\n",
        "    return new_data\r\n",
        "training_set = convert(training_set)\r\n",
        "test_set = convert(test_set)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting the data into Torch Tensors\r\n",
        "\r\n"
      ],
      "metadata": {
        "id": "AMmhuUpldlHo",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "source": [
        "training_set = torch.FloatTensor(training_set)\r\n",
        "test_set = torch.FloatTensor(test_set)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting the ratings into binary ratings 1 (Liked) or 0 (Not Liked)\n"
      ],
      "metadata": {
        "id": "HIPruubGdlPW",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "source": [
        "training_set[training_set == 0] = -1\r\n",
        "training_set[training_set == 1] = 0\r\n",
        "training_set[training_set == 2] = 0\r\n",
        "training_set[training_set >= 3] = 1\r\n",
        "test_set[test_set == 0] = -1\r\n",
        "test_set[test_set == 1 ] = 0\r\n",
        "test_set[test_set == 2] = 0\r\n",
        "test_set[test_set >= 3] = 1 "
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the architecture of the Neural Network\n"
      ],
      "metadata": {
        "id": "6kkL8NkkdlZj",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "source": [
        "class RBM():\r\n",
        "    def __init__(self, nv, nh):\r\n",
        "        self.W = torch.randn(nh, nv)\r\n",
        "        self.a = torch.randn(1, nh)\r\n",
        "        self.b = torch.randn(1, nv)\r\n",
        "    def sample_h(self, x):\r\n",
        "        wx = torch.mm(x, self.W.t())\r\n",
        "        activation = wx + self.a.expand_as(wx)\r\n",
        "        p_h_given_v = torch.sigmoid(activation)\r\n",
        "        return p_h_given_v, torch.bernoulli(p_h_given_v)\r\n",
        "    def sample_v(self, y):\r\n",
        "        wy = torch.mm(y, self.W)\r\n",
        "        activation = wy + self.b.expand_as(wy)\r\n",
        "        p_v_given_h = torch.sigmoid(activation)\r\n",
        "        return p_v_given_h, torch.bernoulli(p_v_given_h)\r\n",
        "    def train(self, v0, vk, ph0, phk):\r\n",
        "        self.W += (torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t()\r\n",
        "        self.b += torch.sum((v0 - vk), 0)\r\n",
        "        self.a += torch.sum((ph0 - phk), 0)\r\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "source": [
        "nv = len(training_set[0])\r\n",
        "nh = 100\r\n",
        "batch_size = 100\r\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "source": [
        "rbm = RBM(nv, nh)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the RBM\n"
      ],
      "metadata": {
        "id": "7gy59alAdloL",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "source": [
        "nb_epoch = 10\r\n",
        "for epoch in range(1, nb_epoch + 1):\r\n",
        "    train_loss = 0\r\n",
        "    train_rmse = 0\r\n",
        "    s = 0.\r\n",
        "    for id_user in range(0, nb_users - batch_size, batch_size):\r\n",
        "        vk = training_set[id_user:id_user+batch_size]\r\n",
        "        v0 = training_set[id_user:id_user+batch_size]\r\n",
        "        ph0,_ = rbm.sample_h(v0)\r\n",
        "        for k in range(10):\r\n",
        "            _,hk = rbm.sample_h(vk)\r\n",
        "            _,vk = rbm.sample_v(hk)\r\n",
        "            vk[v0<0] = v0[v0<0]\r\n",
        "        phk,_ = rbm.sample_h(vk)\r\n",
        "        rbm.train(v0, vk, ph0, phk)\r\n",
        "        train_loss += torch.mean(torch.abs(v0[v0>=0] - vk[v0>=0]))#\r\n",
        "        train_rmse += np.sqrt(torch.mean((v0[v0 >= 0] - vk[v0 >= 0])**2))\r\n",
        "        s += 1.\r\n",
        "    print('epoch : {} | Loss : {} | RMSE : {}'.format(epoch, train_loss/s, train_rmse/s))\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 1 | Loss : 0.3479700982570648 | RMSE : 0.5840339660644531\n",
            "epoch : 2 | Loss : 0.21596258878707886 | RMSE : 0.46370697021484375\n",
            "epoch : 3 | Loss : 0.24536579847335815 | RMSE : 0.4949502944946289\n",
            "epoch : 4 | Loss : 0.24698251485824585 | RMSE : 0.49677684903144836\n",
            "epoch : 5 | Loss : 0.24985729157924652 | RMSE : 0.49960410594940186\n",
            "epoch : 6 | Loss : 0.24552202224731445 | RMSE : 0.49522528052330017\n",
            "epoch : 7 | Loss : 0.24806632101535797 | RMSE : 0.4979269206523895\n",
            "epoch : 8 | Loss : 0.24915306270122528 | RMSE : 0.4989830255508423\n",
            "epoch : 9 | Loss : 0.24926723539829254 | RMSE : 0.49917200207710266\n",
            "epoch : 10 | Loss : 0.2471865862607956 | RMSE : 0.4969930648803711\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the RBM\n"
      ],
      "metadata": {
        "id": "Bak5uc8gd-gX",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "source": [
        "\r\n",
        "\r\n",
        "test_loss = 0\r\n",
        "test_rmse = 0\r\n",
        "s = 0.\r\n",
        "for id_user in range(nb_users):\r\n",
        "    v = training_set[id_user:id_user+1]\r\n",
        "    vt = test_set[id_user:id_user+1]\r\n",
        "    if  len(vt[vt>=0]) > 0:\r\n",
        "        _,h = rbm.sample_h(v)\r\n",
        "        _,v = rbm.sample_v(h)\r\n",
        "        test_loss += torch.mean(torch.abs(vt[vt>=0] - v[vt>=0]))\r\n",
        "        test_rmse += np.sqrt(torch.mean((vt[vt>=0] - v[vt>=0])**2)) \r\n",
        "        s += 1.\r\n",
        "print('loss : {} | RMSE : {}'.format(test_loss/s, test_rmse/s))\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss : 0.24995048344135284 | RMSE : 0.47680291533470154\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {}
    }
  ]
}